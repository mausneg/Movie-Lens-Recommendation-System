{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library yang dibutuhkan dan load dataset yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian mengimport data ratings dengan pandas lalu menampilkan untuk melihat struktur data dari ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas didapatkan informasi sebagai berikut.\n",
    "- Data ratings terdiri dari 100836 baris dan 4 kolom.\n",
    "- Terdapat 3 kolom fitur yaitu `userId`, `movieId`, dan `timestamp`\n",
    "- Terdapat 1 kolom target yaitu `rating`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, mengimport data movies dengan pandas lalu menampilkan untuk melihat struktur data dari movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas didapatkan informasi sebagai berikut.\n",
    "- Data movies terdiri dari 9742 baris dan 3 kolom.\n",
    "- Terdapat 3 kolom fitur yaitu `movieId`,`title`, dan `genres`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu, mengimport data tags dengan pandas lalu menampilkan untuk melihat struktur data dari tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = pd.read_csv('ml-latest-small/tags.csv')\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas didapatkan informasi sebagai berikut.\n",
    "- Data tags terdiri dari 3683 baris dan 4 kolom.\n",
    "- Terdapat 4 kolom fitur yaitu `userId`, `movieId`, `tag`, dan `timestamp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mengecek Tipe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, akan dilakukan pengecekan tipe data dari masing-masing kolom pada data ratings, movies, dan tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tipe data dari semua kolom pada data movies sudah sesuai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tipe data dari semua kolom pada data ratings sudah sesuai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tipe data dari semua kolom pada data tags sudah sesuai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mengecek Missing Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu akan dilakukan pengecekan missing value pada data ratings, movies, dan tags. Hal ini dilakukan agar dataset yang akan digunakan tidak mengandung missing value sehingga tidak menimbulkan error pada saat pemodelan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat missing value pada data movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat missing value pada data ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat missing value pada data tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mengecek Duplikasi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu akan dilakukan pengecekan duplikasi data pada data ratings, movies, dan tags. Hal ini dilakukan agar dataset yang digunakan tidak mengandung duplikasi data yang dapat mempengaruhi hasil analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat duplikasi data pada data movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat duplikasi data pada data ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas tidak terdapat duplikasi data pada data ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mengecek Distribusi Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, akan dilakukan pengecekan distribusi data hanya pada data ratings karena hanya kolom ratings yang memiliki tipe data numerik dan yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas didapatkan informasi sebagai berikut.\n",
    "- Rata-rata dari kolom ratings adalah 3.50\n",
    "- Standar deviasi dari kolom ratings adalah 1.04\n",
    "- Nilai minimum dari kolom ratings adalah 0.50\n",
    "- Nilai 25% dari kolom ratings adalah 3.00\n",
    "- Nilai 50% dari kolom ratings adalah 3.50\n",
    "- Nilai 75% dari kolom ratings adalah 4.00\n",
    "- Nilai maksimum dari kolom ratings adalah 5.00\n",
    "\n",
    "Sehingga dapat disimpulkan bahwa distribusi data dari kolom ratings cenderung menumpuk di nilai 3.00 - 4.00. Hal ini bukanlah menjadi masalah karena data rating merupakan data yang bersifat subjektif dan dapat bervariasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memastikan distribusi data dari kolom ratings, akan dilakukan visualisasi distribusi data dari kolom ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari histogram di atas, grafik terlihat left-skewed yang menunjukkan bahwa mayoritas film memiliki rating di antara 3.0 - 4.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya adalah menggabungkan dataset sesuai dengan kebutuhan. Data ratings akan digabungkan dengan data movies dan data movies juga akan digabungkan dengan data tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Movies dan Data Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penggabungan data movies dengan data tags dilakukan untuk mengetahui kesamaan antar film berdasarkan tag dan genres yang diberikan oleh user. Hal ini akan berguna untuk memberikan rekomendasi film yang memiliki kesamaan berdasarkan genres dan tag yang diberikan oleh user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah pertama adalah menggabungkan setiap tag yang diberikan oleh user berdasarkan `movieId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags = df_tags.groupby('movieId')['tag'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas dapat dilihat kolom tags sudah digabungkan berdasarkan `movieId`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya yaitu mengganti pemisah pada kolom genre menjadi sebuah whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['genres'] = df_movies['genres'].apply(lambda x: x.replace(\"|\",\" \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu akan digabungakan data movies dengan data tags berdasarkan `movieId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_similarity = pd.merge(df_movies,df_tags,how='left',on='movieId')\n",
    "df_movies_similarity.fillna(' ',inplace=True)\n",
    "df_movies_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas dapat dilihat kolom tags sudah digabungkan berdasarkan `movieId` meskipun terdapat beberapa missing value pada kolom tags. Missing value pada kolom tags ini akan diisi dengan whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah Selanjutnya menggabungakan kolom tag dengan kolom genres menjadi satu kolom baru. Hal ini dilakukan agar nantinya dapat digunakan untuk menghitung kesamaan antar film berdasarkan tag dan genres hanya dengan satu kolom saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_similarity['tags'] = df_movies_similarity['genres'] + \" \" + df_movies_similarity['tag']\n",
    "df_movies_similarity.drop(columns=['genres','tag'],inplace=True)\n",
    "df_movies_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Movies dan Data Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, akan dilakukan penggabungan data ratings dengan data movies. Hal ini dilakukan agar nantinya dapat digunakan untuk memberikan rekomendasi film berdasarkan rating yang diberikan oleh user pada movie dengan mempertimbangkan genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_movie= pd.merge(df_ratings,df_movies,how='left',on='movieId')\n",
    "df_ratings_movie.drop(columns=['timestamp'],axis=1,inplace=True)\n",
    "df_ratings_movie['genres'] = df_ratings_movie['genres'].apply(lambda x: np.nan if x == '(no genres listed)' else x)\n",
    "df_ratings_movie.dropna(inplace=True)\n",
    "df_ratings_movie.reset_index()\n",
    "df_ratings_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada output code di atas, data movies dan data ratings sudah digabungkan berdasarkan `movieId`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya yaitu melakukan encoding dengan menjabarkan kolom genres menjadi beberapa kolom berdasarkan nilai yang ada pada kolom genres yang berisi nilai 1 atau 0.\n",
    "Hal ini dilakukan karena model machine learning hanya dapat memproses data yang berupa numerik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_movie['genres'] = df_ratings_movie['genres'].str.split(' ')\n",
    "df_genres = df_ratings_movie['genres'].apply(lambda x: pd.Series([1] * len(x), index=x)).fillna(0).astype(int)\n",
    "df_ratings_encode= pd.concat([df_ratings_movie, df_genres], axis=1)\n",
    "df_ratings_encode.drop(columns=['genres'],inplace=True)\n",
    "df_ratings_encode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas dapat dilihat kolom genres sudah dijabarkan dengan masing-masing jenis genres diwakili oleh satu kolom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan penggabungan data, langkah selanjutnya adalah melakukan transformasi data. Pada tahap ini, data yang berisi rating dan movie akan ditransformasi menjadi data yang berisi user, movie, dan rating. Sehingga data user dan movie akan menjadi X dan data rating akan menjadi y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, akan dilakukan pembuatan data preferensi user berdasarkan rating yang diberikan oleh user pada setiap film dengan mempertimbangkan genres. Sehingga kolom yang tidak diperlukan akan dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_ratings_encode.copy()\n",
    "df_user.drop(columns=['movieId','title'],inplace=True)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya setiap value 1 pada fitur genres akan dikalikan dengan rating yang diberikan oleh user pada film tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 21):\n",
    "    genre_column = df_user.columns[i]\n",
    "    df_user[genre_column] = df_user.apply(lambda row: row['rating'] if row[genre_column] == 1 else np.nan,axis=1)\n",
    "\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu akan dilakukan grouping berdasarkan `userId` dan dengan menghitung rata-rata dari fitur genres, sedangkan kolom rating akan dihapus karena sudah tidak diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = df_user.columns[2:]\n",
    "df_user_avg = df_user.groupby('userId')[genre_columns].mean().reset_index()\n",
    "df_user_avg.fillna(0,inplace=True)\n",
    "df_user_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas menunjukan bahwa data preferensi user sudah berhasil dibuat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya adalah melakukan penggabungan data preferensi user dengan data ratings berdasarkan `userId`. Hal ini bertujuan untuk menggantikan data user dengan data preferensi user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.merge(df_user,df_user_avg,how='left',on='userId')\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya melakukan drop data user yang sudah tidak diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.drop(columns=df_user.columns[1:21],inplace=True)\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu akan dilakukan rename fitur genres yang namanya berubah ketika melakukan penggabungan data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.columns = ['userId'] + genre_columns.tolist()\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, akan dilakukan pembuatan data movie dengan genres dengan menghapus kolom yang tidak berkaitan dengan movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = df_ratings_encode.copy()\n",
    "df_item.drop(columns=['userId','rating','title'],inplace=True)\n",
    "df_item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas, terlihat data movie (yang akan disebut item) yang akan disandingkan dengan data preferensi user (yang akan disebut user) hanya berisi fitur `movieId` dan fitur one hot encoding genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, untuk data rating sebagai Y akan diambil kolom `rating` saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = df_ratings_encode['rating'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu data user dan data item akan di scalling dengan menggunakan Standard Scaler. Alasan Standard Scaler digunakan yaitu karena akan dilakukan pembagian rentang rating, jika value genre bernilai positif menandakan user menyukai film tersebut, sedangkan jika value genre bernilai negatif menandakan user tidak menyukai film tersebut. Atau jika pada data item, value genre bernilai positif menandakan film tersebut memiliki genre tersebut, sedangkan jika value genre bernilai negatif menandakan film tersebut tidak memiliki genre tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_user = StandardScaler()\n",
    "scaler_item = StandardScaler()\n",
    "\n",
    "scaler_user.fit(df_user[genre_columns])\n",
    "scaler_item.fit(df_item[genre_columns])\n",
    "\n",
    "df_user[genre_columns] = scaler_user.transform(df_user[genre_columns])\n",
    "df_item[genre_columns] = scaler_item.transform(df_item[genre_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas jika value genre bernilai positif menandakan user menyukai genre tersebut, sedangkan jika value genre negatif menandakan user tidak menyukai genre tersebut, atau jika value bernilai 0 menandakan user tidak memiliki preferensi terhadap genre tersebut atau user tidak pernah menonton film dengan genre tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas jika value genre bernilai positif menandakan film tersebut memiliki genre tersebut, sedangkan jika value genre negatif menandakan film tersebut tidak memiliki genre tersebut, sedangkan tidak terdapat value 0 karena setiap film pasti memiliki genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dilakukan scalling pada data rating dengan menggunakan MinMaxScaler. Hal ini bertujuan agar data rating memiliki rentang nilai antara 0 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((-1,1))\n",
    "rating = scaler.fit_transform(rating.reshape(-1,1))\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Selanjutnya, data user, data item, dan data rating akan di split menjadi data train, data test, dan data validation. Hal ini bertujuan agar dapat dilakukan evaluasi model machine learning yang akan dibuat. Perbandingan data train, data test, dan data validation yang digunakan adalah 80% data train, 10% data test, dan 10% data validation. Hal ini dipertimbangkan berdasarkan jumlah data yang ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train, user_test, item_train, item_test, rating_train, rating_test = train_test_split(df_user[genre_columns], df_item[genre_columns], rating.flatten(), test_size=0.2, random_state=42)\n",
    "user_test, user_val, item_test, item_val, rating_test, rating_val = train_test_split(user_test, item_test, rating_test, test_size=0.5, random_state=42)\n",
    "\n",
    "user_train.shape, user_test.shape, user_val.shape, item_train.shape, item_test.shape, item_val.shape, rating_train.shape, rating_test.shape, rating_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap selanjutnya yaitu membuat sistem rekomendasi film berdasarkan konten. Pada tahap ini akan dilakukan pembuatan model neural network dengan menggunakan data preferensi user dan data movie. Selain itu juga akan dibuat akan dihitung similarity antar film berdasarkan genres dan tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-Based Item Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada perhitungan similarity antar film berdasarkan genres dan tag, akan digunakan cosine similarity. Hal ini dilakukan karena cosine similarity dapat mengukur kesamaan antar film berdasarkan genres dan tag. Tetapi sebelum itu, akan dilakukan ekstraksi data tags dengan menggunakan CountVectorizer. Dengan menggunakan CountVectorizer, akan dihitung frekuensi kemunculan setiap kata pada kolom tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 5000, lowercase=True)\n",
    "vectors = cv.fit_transform(df_movies_similarity['tags']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dilakukan perhitungan similarity antar vector features tags dengan menggunakan cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosine_sim = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah itu akan dilakukan visualisasi similarity antar film berdasarkan tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cosine_sim)\n",
    "plt.title('Cosine Similarity Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari diagram heatmap di atas, terlihat bahwa banyak daerah yang memiliki warna yang cendrung terang yang menunjukkan bahwa terdapat banyak kesamaan antar film berdasarkan tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dibentuk suatu function yang berfungsi mengambil 10 movie yang memiliki similarity tertinggi berdasarkan tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_movie(title):\n",
    "    index = df_movies_similarity[df_movies_similarity['title'] == title].index[0]\n",
    "    similarity_score = cosine_sim[index] \n",
    "    similarity_place = sorted(enumerate(similarity_score),key=lambda x: x[1],reverse=True)[1:11]\n",
    "    similarity_list = []    \n",
    "    for i in similarity_place:\n",
    "        similarity_list.append([df_movies_similarity.iloc[i[0], 1]] + [i[1]])\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari function di atas, inputan dari function tersebut yaitu judul dari film yang ingin dicari movie yang memiliki similarity tertinggi berdasarkan tags. Nantinya function tersebut akan mengambil similarity movie tersebut dengan movie lainnya berdasarkan indeks. Selanjutnya akan dilakukan sorting, lalu mengambil top 10 movie yang memiliki similarity tertinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_recommendation = get_recommendation_movie('Toy Story (1995)')\n",
    "top_10_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code di atas, terlihat top 10 movie yang memiliki similarity tertinggi dengan movie Toy Story (1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Based Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap selanjutnya yaitu membuat model neural network dengan menggunakan data preferensi user dan data movie. Model neural network yang akan dibuat akan menggunakan data preferensi user dan data movie sebagai X dan data rating sebagai y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 19\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='linear')\n",
    "])\n",
    "\n",
    "item_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='linear')\n",
    "])\n",
    "\n",
    "input_user = tf.keras.Input(shape=(features,))\n",
    "vector_user = user_model(input_user)\n",
    "vector_user = tf.linalg.l2_normalize(vector_user, axis=1)\n",
    "\n",
    "input_item = tf.keras.Input(shape=(features,))\n",
    "vector_item = item_model(input_item)\n",
    "vector_item = tf.linalg.l2_normalize(vector_item, axis=1)\n",
    "\n",
    "output = tf.keras.layers.Dot(axes=1)([vector_user, vector_item])\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_user, input_item], outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada code di atas, secara garis besar terdapat dua model sequential yang akan digunakan. Model sequential pertama yaitu model untuk data user dan model sequential kedua yaitu model untuk data item. Nantinya output dari kedua model tersebut akan digabungkan dengan menggunakan dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dilakukan compile model dengan menggunakan optimizer Adagrad, loss function mean squared error, dan metrics mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01), loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model akan difit dengan menggunakan 100 epochs dan batch size 256. Ini berarti model akan melakukan iterasi sebanyak 100 kali dengan menggunakan 256 data pada setiap iterasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([user_train, item_train], rating_train, epochs=100, verbose=2, batch_size=256, validation_data=([user_val, item_val], rating_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dilakukan prediksi top 10 movie berdasarkan suatu preferensi user. Berikut merupakan contoh preferensi user yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 1000\n",
    "new_adventure = 4\n",
    "new_animation = 5\n",
    "new_children = 4\n",
    "new_comedy = 3\n",
    "new_fantasy = 4\n",
    "new_romance = 1\n",
    "new_action = 3\n",
    "new_crime = 1\n",
    "new_thriller = 1\n",
    "new_mystery = 1\n",
    "new_horror = 1\n",
    "new_drama = 1\n",
    "new_war = 1\n",
    "new_western = 1\n",
    "new_scifi = 1\n",
    "new_musical = 1\n",
    "new_filmnoir = 1\n",
    "new_imax = 1\n",
    "new_documentary = 1\n",
    "\n",
    "new_user = pd.DataFrame([[new_user_id, new_adventure, new_animation, new_children, new_comedy, new_fantasy, new_romance, new_action, new_crime, new_thriller, new_mystery, new_horror, new_drama, new_war, new_western, new_scifi, new_musical, new_filmnoir, new_imax, new_documentary]], columns=['userId', 'Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'Romance', 'Action', 'Crime', 'Thriller', 'Mystery', 'Horror', 'Drama', 'War', 'Western', 'Sci-Fi', 'Musical', 'Film-Noir', 'IMAX', 'Documentary'])\n",
    "new_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari output code tersebut terlihat user 1000 memiliki preferensi terhadap film dengan genres Adventure, Animation, Childern, Fantasy, dan Action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebelum melakukan prediction, akan dilakukan scaling pada data preferensi user 1000 dan juga akan dilakukan penyesuaian dimensi agar dapat digunakan pada model yang telah dibuat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user[genre_columns] = scaler_user.transform(new_user[genre_columns])\n",
    "\n",
    "new_user = np.tile(new_user[genre_columns], (df_item.shape[0], 1))\n",
    "new_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melakukan penyesuaian dimensi maka dimensi dari data user 1000 sama dengan dimensi dari data item yaitu (100789, 19)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya akan dilakukan prediction dengan data user 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([new_user, df_item[genre_columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(predictions)\n",
    "sorted_predictions = np.argsort(predictions, axis=0)[::-1].flatten()\n",
    "sorted_item = df_ratings.index.to_numpy()[sorted_predictions].flatten()\n",
    "sorted_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah dilakukan prediksi, output dari prediksi tersebut akan dilakukan inverse transform dan melakukan sorting untuk mendapatkan top 10 movie yang direkomendasikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_predictions = {\n",
    "    'userId': np.full((df_item.shape[0],), new_user_id),\n",
    "    'index': df_ratings_movie.iloc[sorted_item].index,\n",
    "    'predictions': predictions[sorted_predictions].flatten()\n",
    "} \n",
    "df_predictions = pd.DataFrame(dic_predictions)\n",
    "df_predictions.set_index('index', inplace=True)\n",
    "df_predictions = pd.merge(df_predictions, df_ratings_movie, how='left', left_index=True, right_index=True).reset_index(drop=True)\n",
    "df_predictions.drop_duplicates(subset=['movieId'], inplace=True)\n",
    "df_predictions.drop(columns=['userId_y', 'rating'], inplace=True)\n",
    "df_predictions.rename(columns={'userId_x': 'userId'}, inplace=True)\n",
    "df_predictions.reset_index(drop=True,inplace=True)\n",
    "df_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari ouput code di atas, terlihat top 10 movie yang direkomendasikan untuk user 1000 berdasarkan preferensi user tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah terakhir yaitu melakukan evaluasi model yang telah dibuat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation pertama yaitu melakukan evaluasi model dengan menggunakan data validation. Hal ini bertujuan untuk mengetahui seberapa baik model yang telah dibuat dengan menggunakan data yang belum pernah dilihat sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mse, val_loss = model.evaluate([user_val, item_val], rating_val, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya MSE dari train, test, dan validation akan divisualisasikan agar dapat dilihat perbandingannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(history.history['mse'], label='Training MSE')\n",
    "plt.plot(history.history['val_mse'], label='Validation MSE')\n",
    "plt.plot(val_mse, label='Validation mse', marker='o', markersize=10)\n",
    "plt.legend()\n",
    "plt.title('MSE Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan grafik di atas, terlihat bahwa MSE dari data train, data test, dan data validation cenderung stabil dan tidak terlalu berbeda. Hal ini menunjukkan bahwa model yang telah dibuat tidak overfitting dan tidak underfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
